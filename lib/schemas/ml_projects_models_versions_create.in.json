{
    "type": "object",
    "properties": {
        "parent": {
            "required": true,
            "type": "string"
        },
        "access_token": {
            "type": "string"
        },
        "alt": {
            "type": "string",
            "enum": [
                "json",
                "media",
                "proto"
            ],
            "default": "json"
        },
        "bearer_token": {
            "type": "string"
        },
        "callback": {
            "type": "string"
        },
        "fields": {
            "type": "string"
        },
        "key": {
            "type": "string"
        },
        "oauth_token": {
            "type": "string"
        },
        "pp": {
            "type": "boolean",
            "default": true
        },
        "prettyPrint": {
            "type": "boolean",
            "default": true
        },
        "quotaUser": {
            "type": "string"
        },
        "uploadType": {
            "type": "string"
        },
        "upload_protocol": {
            "type": "string"
        },
        "requestBody": {
            "description": "Represents a version of the model.\n\nEach version is a trained model deployed in the cloud, ready to handle\nprediction requests. A model can have multiple versions. You can get\ninformation about all of the versions of a given model by calling\n[projects.models.versions.list](/ml-engine/reference/rest/v1/projects.models.versions/list).\n\nLINT.IfChange",
            "properties": {
                "autoScaling": {
                    "description": "Automatically scale the number of nodes used to serve the model in\nresponse to increases and decreases in traffic. Care should be\ntaken to ramp up traffic according to the model's ability to scale\nor you will start seeing increases in latency and 429 response codes.",
                    "properties": {
                        "minNodes": {
                            "description": "Optional. The minimum number of nodes to allocate for this model. These\nnodes are always up, starting from the time the model is deployed, so the\ncost of operating this model will be at least\n`rate` * `min_nodes` * number of hours since last billing cycle,\nwhere `rate` is the cost per node-hour as documented in\n[pricing](https://cloud.google.com/ml-engine/pricing#prediction_pricing),\neven if no predictions are performed. There is additional cost for each\nprediction performed.\n\nUnlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least `min_nodes`. You will be charged for the time in which additional\nnodes are used.\n\nIf not specified, `min_nodes` defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.",
                            "format": "int32",
                            "type": "integer"
                        }
                    },
                    "type": "object"
                },
                "createTime": {
                    "description": "Output only. The time the version was created.",
                    "format": "google-datetime",
                    "type": "string"
                },
                "deploymentUri": {
                    "description": "Required. The Google Cloud Storage location of the trained model used to\ncreate the version. See the\n[overview of model\ndeployment](/ml-engine/docs/concepts/deployment-overview) for more\ninformation.\n\nWhen passing Version to\n[projects.models.versions.create](/ml-engine/reference/rest/v1/projects.models.versions/create)\nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can't exceed 1000.",
                    "type": "string"
                },
                "description": {
                    "description": "Optional. The description specified for the version when it was created.",
                    "type": "string"
                },
                "errorMessage": {
                    "description": "Output only. The details of a failure or a cancellation.",
                    "type": "string"
                },
                "etag": {
                    "description": "`etag` is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the `etag` in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An `etag` is returned in the response to `GetVersion`, and\nsystems are expected to put that etag in the request to `UpdateVersion` to\nensure that their change will be applied to the model as intended.",
                    "format": "byte",
                    "type": "string"
                },
                "isDefault": {
                    "description": "Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.\n\nYou can change the default version by calling\n[projects.methods.versions.setDefault](/ml-engine/reference/rest/v1/projects.models.versions/setDefault).",
                    "type": "boolean"
                },
                "labels": {
                    "additionalProperties": {
                        "type": "string"
                    },
                    "description": "Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on\n<a href=\"/ml-engine/docs/how-tos/resource-labels\">using labels</a>.",
                    "type": "object"
                },
                "lastUseTime": {
                    "description": "Output only. The time the version was last used for prediction.",
                    "format": "google-datetime",
                    "type": "string"
                },
                "manualScaling": {
                    "description": "Manually select the number of nodes to use for serving the\nmodel. You should generally use `auto_scaling` with an appropriate\n`min_nodes` instead, but this option is available if you want more\npredictable billing. Beware that latency and error rates will increase\nif the traffic exceeds that capability of the system to serve it based\non the selected number of nodes.",
                    "properties": {
                        "nodes": {
                            "description": "The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to `nodes` * number of hours since\nlast billing cycle plus the cost for each prediction performed.",
                            "format": "int32",
                            "type": "integer"
                        }
                    },
                    "type": "object"
                },
                "name": {
                    "description": "Required.The name specified for the version when it was created.\n\nThe version name must be unique within the model it is created in.",
                    "type": "string"
                },
                "runtimeVersion": {
                    "description": "Optional. The Google Cloud ML runtime version to use for this deployment.\nIf not set, Google Cloud ML will choose a version.",
                    "type": "string"
                },
                "state": {
                    "description": "Output only. The state of a version.",
                    "enum": [
                        "UNKNOWN",
                        "READY",
                        "CREATING",
                        "FAILED",
                        "DELETING"
                    ],
                    "type": "string"
                }
            },
            "type": "object"
        }
    }
}